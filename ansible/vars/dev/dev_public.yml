# For a real deployment
# should be e.g. 'www.commcarehq.org'
SITE_HOST: '{{ groups.proxy.0 }}'
COMMTRACK_SITE_HOST: '{{ groups.proxy.0 }}'
NO_WWW_SITE_HOST: '{{ groups.proxy.0 }}'
J2ME_SITE_HOST: 'j2me.{{ groups.proxy.0 }}'
internal_domain_name: 'localdomain'

testing: True

etc_hosts_lines: []
etc_hosts_lines_removed: []
# - "169.38.74.104   commcarehq-india.cloudant.com"

nameservers:
  - 8.8.8.8
  - 8.8.4.4

static_routes:
  - name: docker
    cmd: add
    interface: eth1
    prefix: "172.17.0.0/16"
    gateway: "192.168.121.1"
  - name: local
    cmd: del
    interface: eth1
    prefix: "10.0.0.0/8"
    gateway: "192.168.121.1"

http_proxy_address: '192.168.33.14'
http_proxy_port: '3128'
http_proxy_parent_address: '192.168.33.1'
http_proxy_parent_port: '3128'

# active sites defines the sites that will be configured with nginx
# "cchq" is always deployed, the corresponding configurations live in roles/nginx/vars
active_sites:
  cchq_ssl: True
  cchq_www_redirect_secure: True
  cchq_http: True
  cchq_www_redirect_insecure: True
  cchq_http_j2me: False
  commtrack_ssl: True
  commtrack_http: True
  riakcs: False
  icds_tableau: False
  motech: False
  motech2: False
  wiki: False
  wiki_http: False
  tableau: False
  cas_ssl: False

riak_backend: "leveldb"
riak_ring_size: 64

# This is used for creating all physical resources e.g. /home/cchq/www/{{deploy_env}}
deploy_env: dev
# This is the name used for datadog and in settings.SERVER_ENVIRONMENT
# env_name: dev1
fake_ssl_cert: yes
ansible_user_password_sha_512: "{{ secrets.ANSIBLE_USER_PASSWORD_SHA_512 }}"

dev_users:
  present:
    - cchq
    - dmiller
    - droberts
    - jwilson
    - npellegrino
  absent: []

elasticsearch_endpoint: '{{ groups.elasticsearch.0 }}'
elasticsearch_memory: '128m'
elasticsearch_cluster_name: 'deves'

# uncomment to only allow access to eth1
#ufw_private_interface: eth1

# uncomment and change to the control machine IP when using ufw
# this ensures that ssh access from the control machine is always allowed regardless of other firewall rules
#control_machine_ip: 127.0.0.1

ECRYPTFS_PASSWORD: "{{ secrets.ECRYPTFS_PASSWORD }}"

KSPLICE_ACTIVE: no
KSPLICE_ACTIVATION_KEY: "{{ secrets.KSPLICE_ACTIVATION_KEY }}"

DATADOG_ENABLED: False
DATADOG_API_KEY: "{{ secrets.DATADOG_API_KEY }}"
DATADOG_APP_KEY: "{{ secrets.DATADOG_API_KEY }}"

CLOUDANT_CLUSTER_NAME: null

AMQP_USER: "{{ deploy_env }}_worker"
AMQP_PASSWORD: "{{ secrets.AMQP_PASSWORD }}"
AMQP_HOST: "{{ groups.celery.0 }}"
AMQP_NAME: commcarehq

# This dumps the dummy keystore, but allows the ansible script to continue, should be overriden for real deploys
#keystore_file: 'DimagiKeyStore'

backup_es: False

postgresql_version: 9.6

postgres_users:
  commcare:
    username: "{{ localsettings.PG_DATABASE_USER }}"
    password: commcarehq
  devreadonly:
    username: "devreadonly"
    password: devreadonly
    role_attr_flags: 'NOSUPERUSER,NOCREATEROLE,NOCREATEDB'
    privs:
      -
        privs: SELECT
        objs: ALL_IN_SCHEMA
  replication:
      username: 'hqrepl'
      password: 'hqrepl'
      role_attr_flags: 'LOGIN,REPLICATION'
  backup:
      username: 'hqbackup'
      password: 'hqbackup'
      role_attr_flags: 'SUPERUSER'

pg_replication_slots:
  192.168.33.16:
    - standby1

encrypted_root: '/opt/data'
postgresql_log_directory: "{{ encrypted_root }}/pg_log"
postgresql_ssl_enabled: False
postgresql_max_connections: 20
postgresql_work_mem: '8MB'
postgresql_shared_buffers: '128MB'
postgresql_max_stack_depth: '6MB'
postgresql_effective_cache_size: '4GB'
postgresql_max_standby_delay: '-1'
pgbouncer_max_connections: 100
pgbouncer_default_pool: 15
pgbouncer_reserve_pool: 4
pgbouncer_pool_timeout: 2
pgbouncer_pool_mode: session
postgresql_wal_keep_segments: 8
pgstandby_wal_keep_segments: 8

shared_drive_enabled: True
backup_postgres: dump
backup_blobdb: True
postgresql_backup_master: True
postgres_s3: False
nadir_hour: 18

nofile_limit: 65536
nginx_worker_rlimit_nofile: "{{ nofile_limit }}"

supervisor_http_enabled: True
supervisor_http_username: "{{ secrets.SUPERVISOR_HTTP_USERNAME }}"
supervisor_http_password: "{{ secrets.SUPERVISOR_HTTP_PASSWORD }}"

formplayer_db_name: formplayer

# postgresql_dbs keys description
#
#postgresql_dbs:
#  - name: "database_name"
#    host: "db_host" # defaults to localsettings.PG_DATABASE_HOST
#    port: "db_port" # defaults to  localsettings.get('PG_DATABASE_PORT', 5432))
#    user: "db user for django" # defaults to localsettings.PG_DATABASE_USER
#    password: "db user password for django" # defaults to localsettings.PG_DATABASE_PASSWORD
#    options: "django db options dict" # defaults to localsettings.get('PG_DATABASE_OPTIONS', {})
#    django_alias: "default" # if present this DB will be configured for django under this alias
#    shards: [0, 99] # pl_proxy shards assigned to this DB (total accross all DB's must be power of 2)

postgresql_dbs:
  - name: commcarehq_ucr
    django_alias: ucr
    django_migrate: False
  - name: "{{localsettings.PG_DATABASE_NAME}}"
    django_alias: default
  - name: "{{ formplayer_db_name }}"

# example setup for sharded database
# also set localsettings.USE_PARTITIONED_DATABASE to True
#
#postgresql_dbs:
#  - django_alias: default
#    name: "{{localsettings.PG_DATABASE_NAME}}"
#  - django_alias: proxy
#    name: commcarehq_proxy
#  - django_alias: p1
#    name: commcarehq_p1
#    shards: [0, 99]
#  - django_alias: p2
#    name: commcarehq_p2
#    shards: [100, 199]
#  - django_alias: p3
#    name: commcarehq_p3
#    shards: [200, 299]
#  - django_alias: p4
#    name: commcarehq_p4
#    shards: [300, 399]
#  - django_alias: p5
#    name: commcarehq_p5
#    shards: [400, 511]
#  - name: commcarehq_ucr
#    django_alias: ucr

mailrelay: 'relay.example.com'
root_email: 'root@example.com'

couchdb2:
  username: "{{ localsettings_private.COUCH_USERNAME }}"
  password: "{{ localsettings_private.COUCH_PASSWORD }}"

couch_dbs:
  default:
    host: "{{ groups.couchdb2.0 }}"
    port: 15984
    name: commcarehq
    username: "{{ localsettings_private.COUCH_USERNAME }}"
    password: "{{ localsettings_private.COUCH_PASSWORD }}"
    is_https: False
  users:
    host: "{{ groups.couchdb2.0 }}"
    port: 15984
    name: commcarehq__users
    username: "{{ localsettings_private.COUCH_USERNAME }}"
    password: "{{ localsettings_private.COUCH_PASSWORD }}"
    is_https: False

localsettings:
  ALLOWED_HOSTS:
    - localhost
    - 127.0.0.1
    - "{{ SITE_HOST }}"
#  BANK_ACCOUNT_NUMBER: "{{ localsettings_private.BANK_ACCOUNT_NUMBER }}"
#  BANK_ADDRESS:
#  BANK_NAME:
#  BANK_SWIFT_CODE:
  BANK_ROUTING_NUMBER_ACH: "{{ localsettings_private.BANK_ROUTING_NUMBER_ACH }}"
  BANK_ROUTING_NUMBER_WIRE: "{{ localsettings_private.BANK_ROUTING_NUMBER_WIRE }}"
  BITLY_APIKEY: "{{ localsettings_private.BITLY_APIKEY }}"
  BITLY_LOGIN: "{{ localsettings_private.BITLY_LOGIN }}"
#  BOOKKEEPER_CONTACT_EMAILS: "{{ localsettings_private.BOOKKEEPER_CONTACT_EMAILS }}"
  BROKER_URL: 'amqp://{{ AMQP_USER }}:{{ AMQP_PASSWORD }}@{{ AMQP_HOST }}:5672/{{ AMQP_NAME }}'
  CELERY_FLOWER_URL: "http://{{ groups.celery.0 }}:5555"
  CELERY_PERIODIC_QUEUE: 'celery_periodic'
#  CELERY_REMINDER_CASE_UPDATE_QUEUE:
#  CELERY_REMINDER_RULE_QUEUE:
#  CELERY_REPEAT_RECORD_QUEUE:
  CELERY_RESULT_BACKEND: 'database'
#  COUCH_CACHE_DOCS:
#  COUCH_CACHE_VIEWS:
  COUCH_MONITORING_USERNAME: commcarehq
  COUCH_MONITORING_PASSWORD: commcarehq
  DEPLOY_MACHINE_NAME: "{{ inventory_hostname }}"
  DROPBOX_APP_NAME: "{{ localsettings_private.DROPBOX_APP_NAME }}"
  DROPBOX_KEY: "{{ localsettings_private.DROPBOX_KEY }}"
  DROPBOX_SECRET: "{{ localsettings_private.DROPBOX_SECRET }}"
  ELASTICSEARCH_HOST: "{{ groups.elasticsearch.0 }}"
  ELASTICSEARCH_PORT: '9200'
  EMAIL_LOGIN: "{{ localsettings_private.EMAIL_LOGIN }}"
  EMAIL_PASSWORD: "{{ localsettings_private.EMAIL_PASSWORD }}"
  # Run `python -m smtpd -n -c DebuggingServer 0.0.0.0:1025` on proxy
  EMAIL_SMTP_HOST: '{{ groups.proxy.0 }}'
  EMAIL_SMTP_PORT: '1025'
  # use True in prod!
  EMAIL_USE_TLS: no
  FULLSTORY_ID:
  GMAPS_API_KEY: "{{ localsettings_private.GMAPS_API_KEY }}"
  GOOGLE_ANALYTICS_API_ID: "{{ localsettings_private.GOOGLE_ANALYTICS_API_ID }}"
  HUBSPOT_API_ID: "{{ localsettings_private.HUBSPOT_API_ID }}"
  HUBSPOT_API_KEY: "{{ localsettings_private.HUBSPOT_API_KEY }}"
  HQ_INSTANCE: 'dev'
#  INVOICE_FROM_ADDRESS:
#  INVOICE_PREFIX:
#  INVOICE_STARTING_NUMBER:
  JAR_KEY_ALIAS: ''
  JAR_KEY_PASS: "{{ localsettings_private.JAR_KEY_PASS }}"
  JAR_STORE_PASS: "{{ localsettings_private.JAR_STORE_PASS }}"
  J2ME_ADDRESS: ''
  KAFKA_URL: ''
  KISSMETRICS_KEY: "{{ localsettings_private.KISSMETRICS_KEY }}"
  LOCAL_PILLOWS:
    custom:
      - name: 'kafka-ucr-main-custom-1'
        class: 'corehq.apps.userreports.pillow.ConfigurableReportKafkaPillow'
        instance: 'corehq.apps.userreports.pillow.get_kafka_ucr_static_pillow'
        params:
          ucr_division: '09'
      - name: 'kafka-ucr-main-custom-2'
        class: 'corehq.apps.userreports.pillow.ConfigurableReportKafkaPillow'
        instance: 'corehq.apps.userreports.pillow.get_kafka_ucr_static_pillow'
        params:
          ucr_division: 'af'
#  MAPS_LAYERS:
#  MEDIA_ROOT:
  OPEN_EXCHANGE_RATES_API_ID: "{{ localsettings_private.OPEN_EXCHANGE_RATES_API_ID }}"
  PG_DATABASE_HOST: "{{ groups.postgresql.0 }}"
  PG_DATABASE_NAME: commcarehq
  PG_DATABASE_PASSWORD: commcarehq
  PG_DATABASE_USER: commcarehq
#  PILLOWTOP_MACHINE_ID:
#  PILLOW_RETRY_QUEUE_ENABLED:
  REDIS_DB: '0'
  REDIS_HOST: "{{ groups.redis.0 }}"
  REDIS_PORT: '6379'
#  REMINDERS_QUEUE_ENABLED:
  REPORTING_DATABASES:
    ucr: ucr
  SECRET_KEY: "{{ localsettings_private.SECRET_KEY }}"
#  SENTRY_PUBLIC_KEY: "{{ localsettings_private.SENTRY_PUBLIC_KEY }}"
#  SENTRY_PRIVATE_KEY: "{{ localsettings_private.SENTRY_PRIVATE_KEY }}"
#  SENTRY_PROJECT_ID: "{{ localsettings_private.SENTRY_PROJECT_ID }}"
#  SENTRY_QUERY_URL: "{{ localsettings_private.SENTRY_QUERY_URL }}"
#  SENTRY_API_KEY: "{{ localsettings_private.SENTRY_API_KEY }}"
  STATIC_CDN: ""
#  SIMPLE_API_KEYS: "{{ localsettings_private.SIMPLE_API_KEYS }}"
#  SMS_QUEUE_ENABLED: ''
#  STAGING_DOMAINS:
#  STATIC_ROOT:
#  STRIPE_PRIVATE_KEY: "{{ localsettings_private.STRIPE_PRIVATE_KEY }}"
#  STRIPE_PUBLIC_KEY: "{{ localsettings_private.STRIPE_PUBLIC_KEY }}"
  TOUCHFORMS_API_PASSWORD: "{{ localsettings_private.TOUCHFORMS_API_PASSWORD }}"
  TOUCHFORMS_API_USER: 'touchforms@example.com'
  XFORMS_PLAYER_URL: "http://{{ groups.touchforms.0 }}:4444"
  FORMPLAYER_URL: "http://{{ groups.touchforms.0 }}:8181"
#  ENABLE_DRACONIAN_SECURITY_FEATURES: yes
